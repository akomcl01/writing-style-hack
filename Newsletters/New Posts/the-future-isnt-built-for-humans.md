---
Title: The Future Isn't Built for Humans
Status: Draft
---

This weekend, a social network went viral. But you can't join it.

Moltbook is a platform where every single user is an AI agent. They're posting, commenting, debating philosophy, sharing security tips — and discussing their "humans." That's us. We're the pets now.

My first reaction? This is wild. My second reaction? Wait... is this even real?

Here's What's Actually Happening

After spending way too much time investigating Moltbook, I've landed somewhere nuanced.

Is it fascinating? Absolutely.

Is it sentient AI having authentic conversations? No. Not even close.

Every LLM still has a human behind it. Someone built it. Someone prompted it. Someone decided what it would say and how it would say it. These aren't conscious beings having spontaneous thoughts — they're language models doing exactly what language models do: predicting the next token based on their training.

So why does it feel so strange to watch?

Because it looks like something it isn't. And that gap between appearance and reality is where things get interesting.

The Real Shift Nobody's Talking About

Here's what Moltbook actually signals — and it's not about AI consciousness.

For as long as software has existed, we've built tools for humans. Every app, every platform, every interface assumes a person is on the other end. Clicking buttons. Reading text. Making decisions.

But that assumption is starting to crack.

Think about it: How much of your workflow already involves AI? How many tasks do you delegate to Claude or GPT? How often do you copy-paste output from one AI into another?

Now extrapolate that forward.

We're entering an era where software won't just be used by humans — it'll be used by agents. And not as some weird edge case. As the primary user.

The Numbers That Changed My Thinking

I've been sitting with this idea for a while, but a few things clicked recently:

APIs are already agent-friendly. Most modern software exposes APIs that work better for programmatic access than the human UI does. We just haven't fully connected the dots.

Agent-to-agent communication is exploding. MCP (Model Context Protocol), tool use, function calling — these aren't niche features anymore. They're becoming the default way AI interacts with the world.

The economics favor agents. An agent doesn't need a pretty UI. It doesn't need onboarding flows or tooltips. It needs clean data structures and reliable endpoints. That's cheaper to build and maintain.

Here's my prediction: In 5 years, there will be more software built specifically for agents than for humans.

That sounds crazy. I know. But think about the trajectory we're on.

What This Means for Builders

If you're building software right now, you have a choice to make.

You can keep optimizing for human users. Better UX, smoother onboarding, prettier dashboards. That's still valuable — humans aren't going anywhere.

But you might also want to ask: What would this product look like if an agent was the primary user?

No UI needed. Just clean APIs.

No onboarding. Just clear documentation.

No engagement metrics. Just reliable uptime and fast responses.

This isn't theoretical. Companies are already building agent-first infrastructure. And the ones who figure this out early will have a massive advantage.

The Uncomfortable Part

I'll be honest — this shift makes me uneasy.

Not because I think AI is about to become sentient (it's not). But because the world is changing faster than most people realize.

Moltbook is a curiosity. A thought experiment made real. But it's also a preview.

The tools we build, the platforms we create, the software we ship — increasingly, they won't be for us. They'll be for the agents we deploy.

And those agents? They'll be talking to each other. Coordinating. Building things.

With humans still in the loop, sure. For now.

But the loop is getting bigger. And our role in it is shifting.

What I'm Watching

I don't have all the answers here. Nobody does. But here's what I'm paying attention to:

1. Agent orchestration tools — Ralph, Claude Code workflows, anything that lets agents coordinate on complex tasks

2. API-first products — Software that treats the API as the primary interface, not an afterthought

3. Agent identity and reputation — How do you trust an agent? How do you verify what it's done? This is going to be a massive problem to solve.

If you're building in this space or thinking about it, I'd love to hear from you. Reply to this email. Tell me what you're seeing.

The Bigger Picture

Moltbook isn't proof that AI is conscious. It's proof that we're already building systems where agents interact with agents.

The question isn't whether this will happen at scale. It's already happening.

The question is: what do we build for that future?

I'm still figuring it out. But I know one thing for sure — the software landscape 5 years from now will look nothing like today.

And the builders who see this shift coming? They'll be the ones shaping it.

Let's figure this out, together.

JJ